apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: kube-prometheus-stack
  namespace: prometheus
spec:
  chart:
    spec:
      chart: kube-prometheus-stack
      version: 66.3.0
      reconcileStrategy: ChartVersion
      sourceRef:
        kind: HelmRepository
        namespace: flux-system
        name: prometheus-community
  install:
    crds: Create
  upgrade:
    crds: CreateReplace
  interval: 1h
  driftDetection:
    mode: enabled
    ignore:
      # Ignore "validated" annotation which is not inserted during install
      - target:
          kind: PrometheusRule
        paths:
          - /metadata/annotations/prometheus-operator-validated
  values:
    grafana:
      adminPassword: ${grafana_admin_password}
      podLabels:
        policy.gabe565.com/egress-ingress: "true"
        policy.gabe565.com/egress-kubeapi: "true"
        policy.gabe565.com/egress-namespace: "true"
        policy.gabe565.com/egress-world: "true"
        policy.gabe565.com/ingress-ingress: "true"
        policy.gabe565.com/ingress-namespace: "true"
      deploymentStrategy:
        type: Recreate
      defaultDashboardsTimezone: browser
      grafana.ini:
        server:
          root_url: https://${grafana_url}
        auth:
          signout_redirect_url: https://${oauth_host}/application/o/grafana/end-session/
          oauth_auto_login: true
        auth.generic_oauth:
          name: Authentik
          enabled: true
          scopes: openid email profile
          auth_url: https://${oauth_host}/application/o/authorize/
          token_url: https://${oauth_host}/application/o/token/
          api_url: https://${oauth_host}/application/o/userinfo/
          role_attribute_path: contains(groups[*], 'Grafana Admins') && 'Admin' || contains(groups[*], 'Grafana Editors') && 'Editor' || 'Viewer'
      env:
        GF_AUTH_GENERIC_OAUTH_CLIENT_ID: ${oauth_client_id}
        GF_AUTH_GENERIC_OAUTH_CLIENT_SECRET: ${oauth_client_secret}
      ingress:
        enabled: true
        hosts:
          - ${grafana_url}
        tls:
          - secretName: ${certificate_name}
            hosts:
              - ${grafana_url}
      persistence:
        type: pvc
        enabled: true
        accessModes: [ReadWriteOnce]
        size: 10Gi
    defaultRules:
      disabled:
        KubeControllerManagerDown: true
        KubeProxyDown: true
        KubeSchedulerDown: true
        NodeRAIDDegraded: true
    additionalPrometheusRulesMap:
      node-exporter-custom:
        groups:
          - name: node-exporter-custom
            rules:
              - alert: NodeRAIDDegraded
                annotations:
                  description: RAID array '{{ $labels.device }}' at {{ $labels.instance }} is
                    in degraded state due to one or more disks failures. Number of spare drives
                    is insufficient to fix issue automatically.
                  runbook_url: https://runbooks.prometheus-operator.dev/runbooks/node/noderaiddegraded
                  summary: RAID Array is degraded.
                expr: 4 - node_md_disks{state="active",job="node-exporter",device=~"(/dev/)?(mmcblk.p.+|nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|md.+|dasd.+)"} > 0
                for: 15m
                labels:
                  severity: critical
    alertmanager:
      alertmanagerSpec:
        podMetadata:
          labels:
            policy.gabe565.com/egress-namespace: "true"
            policy.gabe565.com/egress-world: "true"
            policy.gabe565.com/ingress-namespace: "true"
        storage:
          volumeClaimTemplate:
            spec:
              accessModes: [ReadWriteOnce]
              resources:
                requests:
                  storage: 10Gi
      config:
        route:
          receiver: telegram
        receivers:
          - name: "null"
          - name: telegram
            telegram_configs:
              - bot_token: ${telegram_bot_token}
                chat_id: ${telegram_chat_id}
                send_resolved: false
    prometheus:
      prometheusSpec:
        podMetadata:
          labels:
            policy.gabe565.com/egress-headscale: "true"
            policy.gabe565.com/egress-nodes: "true"
            policy.gabe565.com/egress-namespace: "true"
            policy.gabe565.com/egress-world: "true"
            policy.gabe565.com/ingress-namespace: "true"
        enableRemoteWriteReceiver: true
        podMonitorSelectorNilUsesHelmValues: false
        serviceMonitorSelectorNilUsesHelmValues: false
        scrapeConfigSelectorNilUsesHelmValues: false
        scrapeInterval: 1m
        evaluationInterval: 1m
        resources:
          requests:
            memory: 3Gi
          limits:
            memory: 6Gi
        containers:
          - name: vpn
            image: ghcr.io/tailscale/tailscale:v1.76.6
            env:
              - name: TS_HOSTNAME
                value: prometheus
              - name: TS_EXTRA_ARGS
                value: --login-server=https://${vpn_host}
              - name: TS_KUBE_SECRET
                value: tailscale-state
              - name: TS_AUTHKEY
                value: ${vpn_auth_key}
              - name: TS_NO_LOGS_NO_SUPPORT
                value: "true"
            livenessProbe: &probe
              exec:
                command: [tailscale, --socket=/tmp/tailscaled.sock, status]
              periodSeconds: 60
            startupProbe:
              <<: *probe
              failureThreshold: 60
              periodSeconds: 5
        storageSpec:
          volumeClaimTemplate:
            spec:
              accessModes: [ReadWriteOnce]
              resources:
                requests:
                  storage: 50Gi
      ingress:
        enabled: true
        annotations:
          nginx.ingress.kubernetes.io/auth-url: |-
            http://ak-outpost-gabernetes.authentik.svc.cluster.local:9000/outpost.goauthentik.io/auth/nginx
          nginx.ingress.kubernetes.io/auth-signin: |-
            /outpost.goauthentik.io/start?rd=$escaped_request_uri
          nginx.ingress.kubernetes.io/auth-response-headers: |-
            Set-Cookie,X-authentik-username,X-authentik-groups,X-authentik-email,X-authentik-name,X-authentik-uid
          nginx.ingress.kubernetes.io/auth-snippet: |
            proxy_set_header X-Forwarded-Host $http_host;
          nginx.ingress.kubernetes.io/client-body-buffer-size: 128k
          nginx.ingress.kubernetes.io/enable-access-log: "false"
          nginx.ingress.kubernetes.io/satisfy: any
          nginx.ingress.kubernetes.io/whitelist-source-range: ${ingress_whitelist}
        hosts:
          - ${prometheus_url}
        tls:
          - secretName: ${certificate_name}
            hosts:
              - ${prometheus_url}
    prometheusOperator:
      networkPolicy:
        enabled: true
        flavor: cilium
      podLabels:
        policy.gabe565.com/egress-kubeapi: "true"
        policy.gabe565.com/egress-namespace: "true"
        policy.gabe565.com/ingress-namespace: "true"
    kube-state-metrics:
      customLabels:
        policy.gabe565.com/egress-kubeapi: "true"
